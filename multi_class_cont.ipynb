{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc9c538ff684bdcac39620497952c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=1, description='Diagnoses', max=10, min=1), VBox(children=(VBox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets, VBox, HBox, Layout, Output, Label\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "\n",
    "def softmax_regression_predict(pre_test_probabilities, weights_of_evidence):\n",
    "    if len(pre_test_probabilities) != len(weights_of_evidence):\n",
    "        raise ValueError(\"Lengths of pre_test_probabilities and weights_of_evidence must match.\")\n",
    "    \n",
    "    # Convert pre-test probabilities to logs; add the log-likelihood ratio\n",
    "    combined = np.log(pre_test_probabilities) + np.array(weights_of_evidence)\n",
    "    \n",
    "    # Softmax for final probabilities\n",
    "    exp_combined = np.exp(combined - np.max(combined))  # Stability trick\n",
    "    probabilities = exp_combined / np.sum(exp_combined)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def stacked_chart_pre_post(pre_test_probabilities, post_testing_probabilities, dx_names, weights_of_evidence, figsize=(6, 6)):\n",
    "    \"\"\"Visualize the changes in probabilities with dotted lines connecting the top and bottom of pre- and post-test bars.\"\"\"\n",
    "    # Check that input lengths match\n",
    "    if not (len(pre_test_probabilities) == len(post_testing_probabilities) == len(dx_names) == len(weights_of_evidence)):\n",
    "        raise ValueError(\"All input arrays must have the same length.\")\n",
    "\n",
    "    # Normalize the probabilities to ensure they sum to 1\n",
    "    pre_test_probabilities = np.array(pre_test_probabilities) / np.sum(pre_test_probabilities)\n",
    "    post_testing_probabilities = np.array(post_testing_probabilities) / np.sum(post_testing_probabilities)\n",
    "\n",
    "    # Combine the data for stacked bar charts\n",
    "    data = [pre_test_probabilities, post_testing_probabilities]\n",
    "\n",
    "    # Labels for the x-axis\n",
    "    x_labels = [\"Before Info\", \"After Info\"]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Stacked bar chart\n",
    "    x = np.arange(len(data))  # Positions for \"Before\" and \"After\"\n",
    "    bottoms = np.zeros(len(data))  # To track stack heights\n",
    "    width = 0.12  # Increased bar width for better visibility\n",
    "\n",
    "    # Store top and bottom coordinates for dotted line drawing\n",
    "    bar_tops = {i: [] for i in range(len(dx_names))}\n",
    "    bar_bottoms = {i: [] for i in range(len(dx_names))}\n",
    "\n",
    "    # Add bars and annotate probabilities\n",
    "    for i, category in enumerate(dx_names):\n",
    "        values = [data_point[i] for data_point in data]\n",
    "        bars = ax.bar(x, values, width=width, bottom=bottoms, label=f\"{category} (Cumulative LR: {np.exp(weights_of_evidence[i]):.2f})\")\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            # Add text inside each bar\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_y() + bar.get_height() / 2,\n",
    "                f\"{value:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=10,\n",
    "                color=\"white\"\n",
    "            )\n",
    "            # Store the top and bottom of each bar\n",
    "            bar_tops[i].append(bar.get_y() + bar.get_height())\n",
    "            bar_bottoms[i].append(bar.get_y())\n",
    "\n",
    "        bottoms += values\n",
    "\n",
    "    # Add dotted lines connecting the top and bottom of each category\n",
    "    for i in range(len(dx_names)):\n",
    "        ax.plot(\n",
    "            x,  # x-coordinates for \"Before\" and \"After\"\n",
    "            bar_tops[i],  # y-coordinates for the tops of the bars\n",
    "            linestyle=\"--\", color=\"gray\", alpha=0.5\n",
    "        )\n",
    "        ax.plot(\n",
    "            x,  # x-coordinates for \"Before\" and \"After\"\n",
    "            bar_bottoms[i],  # y-coordinates for the bottoms of the bars\n",
    "            linestyle=\"--\", color=\"gray\", alpha=0.5\n",
    "        )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_title(\"Before-Data vs After-Data Probabilities\")\n",
    "\n",
    "    # Move the legend below the chart\n",
    "    ax.legend(title=\"Diagnoses\", loc=\"best\", bbox_to_anchor=(0.5, -0.15), ncol=1)\n",
    "\n",
    "    # Adjust layout to avoid overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generalized_predictor_wrapper(diagnoses):\n",
    "    \"\"\"\n",
    "    diagnoses = list of dicts:\n",
    "    [\n",
    "      { 'name': <str>, 'pretest': <float from 0 to 1>, 'loglr': <float from -5 to +5> },\n",
    "      ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pre_test_probs = []\n",
    "    weights_of_evidence = []\n",
    "    names = []\n",
    "    \n",
    "    for diag in diagnoses:\n",
    "        names.append(diag['name'])\n",
    "        pre_test_probs.append(diag['pretest'])\n",
    "        weights_of_evidence.append(diag['loglr'])\n",
    "\n",
    "    pre_test_sum = sum(pre_test_probs)\n",
    "    norm_pre_test_probs = [p / pre_test_sum for p in pre_test_probs]\n",
    "\n",
    "    predicted_probs = softmax_regression_predict(norm_pre_test_probs, weights_of_evidence) # doesn't need to be norm'd\n",
    "    \n",
    "    # Display the results\n",
    "    print(f\"{'Diagnosis':<20}{'Pre-Test Pr':<15}{'Norm. Pre-Test':<15}{'Total LR':<15}{'LogLR':<15}{'Post-Test Pr':<15}\")\n",
    "    print(\"-\" * 95)\n",
    "    for i, name in enumerate(names):\n",
    "        print(f\"{name:<20}{pre_test_probs[i]:<15.2f}{norm_pre_test_probs[i]:<15.2f}{np.exp(weights_of_evidence[i]):<15.2f}{weights_of_evidence[i]:<15.2f}{predicted_probs[i]:<15.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'names': names,\n",
    "        'pre_test_probs': pre_test_probs,\n",
    "        'weights_of_evidence': weights_of_evidence,\n",
    "        'predicted_probs': predicted_probs\n",
    "    }\n",
    "\n",
    "\n",
    "def create_diagnosis_widget():\n",
    "    diagnosis_count = widgets.IntSlider(\n",
    "        value=1, min=1, max=10, step=1, description=\"Diagnoses\"\n",
    "    )\n",
    "    container = VBox()\n",
    "    chart_output = Output()\n",
    "\n",
    "    def update_widgets(change):\n",
    "        if change['name'] == 'value':\n",
    "            container.children = []\n",
    "            for i in range(change['new']):\n",
    "                name_widget = widgets.Text(\n",
    "                    value=f\"Diagnosis {i+1}\",\n",
    "                    description=\"Name:\"\n",
    "                )\n",
    "                \n",
    "                # Pre-test probability slider from 0.0 to 1.0, 2-decimal readout\n",
    "                pretest_widget = widgets.FloatSlider(\n",
    "                    value=0.5,\n",
    "                    min=0.0,\n",
    "                    max=1.0,\n",
    "                    step=0.01,\n",
    "                    description=\"Pre-Test:\",\n",
    "                    readout_format='.2f'\n",
    "                )\n",
    "\n",
    "                # Create the LogLR FloatLogSlider\n",
    "                loglr_widget = widgets.FloatLogSlider(\n",
    "                    value=1.0,            # Start with LR = 1\n",
    "                    base=np.e,            # Base e\n",
    "                    min=-5.0,             # Minimum LogLR\n",
    "                    max=5.0,              # Maximum LogLR\n",
    "                    step=0.1,             # Step size\n",
    "                    description=\"Total LR:\", # Label for the slider\n",
    "                    readout=True,\n",
    "                    readout_format=\".2f\"\n",
    "                )\n",
    "\n",
    "                diagnosis_box = VBox([\n",
    "                    name_widget,\n",
    "                    pretest_widget,\n",
    "                    loglr_widget,\n",
    "                ])\n",
    "                container.children += (diagnosis_box,)\n",
    "\n",
    "    diagnosis_count.observe(update_widgets, names='value')\n",
    "    \n",
    "    # Force the initial layout\n",
    "    update_widgets({'name': 'value', 'new': diagnosis_count.value})\n",
    "\n",
    "    def gather_inputs(_):\n",
    "        diagnoses = []\n",
    "        for diagnosis_box in container.children:\n",
    "            name = diagnosis_box.children[0].value\n",
    "            pretest = diagnosis_box.children[1].value\n",
    "            loglr = np.log(diagnosis_box.children[2].value)  # Transform LR back to LogLR\n",
    "\n",
    "            diagnoses.append({\n",
    "                'name': name,\n",
    "                'pretest': pretest,\n",
    "                'loglr': loglr\n",
    "            })\n",
    "\n",
    "        chart_output.clear_output()\n",
    "        with chart_output:\n",
    "            results = generalized_predictor_wrapper(diagnoses)\n",
    "            stacked_chart_pre_post(\n",
    "                results['pre_test_probs'],\n",
    "                results['predicted_probs'],\n",
    "                results['names'],\n",
    "                results['weights_of_evidence']\n",
    "            )\n",
    "\n",
    "    calculate_button = widgets.Button(description=\"Calculate\")\n",
    "    calculate_button.on_click(gather_inputs)\n",
    "\n",
    "    return HBox([VBox([diagnosis_count, container, calculate_button]), chart_output])\n",
    "\n",
    "\n",
    "# Now create and display the revised widget\n",
    "diagnosis_widget = create_diagnosis_widget()\n",
    "display(diagnosis_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the intuition for the problem: \n",
    "\n",
    "We are asking the LLM (or, the literature) to estimate multiple one diagnosis vs the rest likelihood ratios (ie the likelihood if diagnosis over likelihood if not diagnosis). \n",
    "\n",
    "For example, consider the case where there's 3 diagnoses under consideration: It's either A, B, or C (more precisely, let's say it's 1 and only 1 of A, B, or C). This means that the pre-test probabilities must sum to 1. \n",
    "\n",
    "If we then gather a new piece of information, we get 3 likelihood ratios\n",
    "\n",
    "- A vs not A (== B or C). This is LR1\n",
    "- B vs not B (== A or C). This is LR2\n",
    "- C vs not C (== A or B). This is LR3 \n",
    "\n",
    "Because all three LRs refer to the same patient and the same piece of data - they must all be *true at once*.  And, because even after the new piece of information is incorporated, all post-test probabilities must sum to 1. This is called coherence. \n",
    "\n",
    "Because we have estimated each one-vs-rest (OVR) likelihood ratio (e.g. LR for A vs not A) independently and imperfectly, when the LRs are applied the resulting post-test probabilities may not sum to 1 - which is called incoherence. Conversely, if we apply all the OVR likelihoods and the resulting post-test probabilities do sum to 1, the LRs are coherent. \n",
    "\n",
    "The naive way - and what I initially did - was to apply all the one-vs-rest likelihood ratios to update each pre-test probability, then re-scale the resulting post-test probabilities so that they sum to 1. \n",
    "\n",
    "This is problematic because it breaks the Bayes odds–LR identity and therefore distorts the way evidence updates the probabilities. You can see this by considering: \n",
    "\n",
    "When an LR of 2 is applied to a situation where the pre-test probability is 50% (1:1 odds), the post-test probability is 66% (2:1 odds) - a 16% probability difference. When an LR of 2 is applied to a situation where the pre-test probability was 90% (9:1 odds), the post-test probability is 94.7% (18:1), a less than 5% difference. \n",
    "\n",
    "So, normalizing in probability space (rather than log-odds space) implies that you actually updated with a different LR that differs based on the probability of the diagnosis. The naive probability normalization dilutes strong (probable) diagnoses and inflates weak (improbable) ones.\n",
    "\n",
    "Consider: \n",
    "- Priors (A- 0.50, B- 0.30, C- 0.20); \n",
    "- LLM estimated OVR LRs (4, 3, 2).\n",
    "- Binary posteriors (slices): q=(0.800, 0.563, 0.333); sum s=1.696 == non-coherent\n",
    "- Renormalize in probability space => P=(0.472, 0.332, 0.197).\n",
    "- Implied OVR LRs from the bayesian update P: (0.893, 1.158, 0.979) — nowhere near (4, 3, 2)! \n",
    "\n",
    "That’s the odds–LR mismatch we're trying to solve\n",
    "\n",
    "So, an alternative way to solve this 'coupling problem' would be to rescale the estimated LRs in log-odds space - dividing or multiplying them all by some factor such that the set of OVR LRs are consistent (== result in post-test probabilities that sum to 1). This would work (it's whats called an intercept‑only calibration; it fixes a global bias but can’t correct class‑specific errors), but an even better approach is to consider that the existing LRs are some sort of best guess that may follow a normal distribution (ie result from random additive factors pushing the estimate erroneously in either direction), and that we can fit a set of LRs to the guesses that minimizes the squared error. \n",
    "\n",
    "Retinkered, with Bayes-coherent OVR LR Solver: \n",
    "- Priors (A- 0.50, B- 0.30, C- 0.20); \n",
    "- LLM estimated OVR LRs (4, 3, 2).\n",
    "- Renormalized OVR LRs (1.08, .99, .905)\n",
    "- Resulting Post-test probabilities => P=(0.52, 0.3, 0.18).\n",
    "\n",
    "In essence, we are are fitting class “scores” that define a single multiclass model but are estimated noisily; the fitted model is the best one (closest squared error) that implies a coherent set of OVR LRs (ie. a posterior that sums to 1).\n",
    "\n",
    "That's what the new algorithm does (with an additional L2 regularization step to ensure that extreme values don't make the problem too hard/unstable to numerically solve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9834477e96e4d848afbebd5383d91b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=3, description='Diagnoses', max=12, min=1), Dropdown(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets, VBox, HBox, Layout, Output, Label\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.special import expit, logsumexp\n",
    "\n",
    "# Optional styling\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "# ============================================================\n",
    "#  Bayes‑coherent OVR solver: concepts and data flow\n",
    "#  -----------------------------------------------------------\n",
    "#  • priors π_k (pre‑test probabilities) – sum to 1\n",
    "#  • OVR LRs λ_k  (diagnosis k vs \"not k\") – possibly inconsistent\n",
    "#  • We seek class log‑*scores* s_k (roughly, log likelihoods) so that:\n",
    "#       model_logLR_k = s_k - log(∑_{j≠k} π_j e^{s_j}) + log(1-π_k)\n",
    "#    matches the input log λ_k in least‑squares sense.\n",
    "#  • Then posterior P_k ∝ π_k e^{s_k} is Bayes‑coherent by construction.\n",
    "#  • L2 regularization on s controls numeric stability / overfitting.\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class OVRProjectionResult:\n",
    "    posterior: np.ndarray                 # Coherent posterior P_k = softmax(log π_k + s_k)\n",
    "    log_scores: np.ndarray                # s_k with one baseline fixed to 0 (identifiability)\n",
    "    lr_vs_baseline: np.ndarray            # Common-reference LRs: LR_{k:baseline} = exp(s_k)\n",
    "    ovr_lr_fitted: np.ndarray             # Coherent OVR LRs implied by the fitted s\n",
    "    rmse: float                           # RMS residual on log-LR scale (closeness to inputs)\n",
    "    success: bool\n",
    "    message: str\n",
    "    nfev: int\n",
    "    diagnostics: Dict[str, Any]           # Helpful extras: baseline index, sum_q_init, etc.\n",
    "\n",
    "\n",
    "def project_ovr_to_coherent(\n",
    "    priors: np.ndarray,\n",
    "    ovr_lr: np.ndarray,\n",
    "    weights: Optional[np.ndarray] = None,\n",
    "    baseline: Optional[int] = None,\n",
    "    reg: float = 0.0,\n",
    "    max_nfev: int = 200,\n",
    "    ftol: float = 1e-10,\n",
    "    xtol: float = 1e-10,\n",
    "    gtol: float = 1e-10,\n",
    ") -> OVRProjectionResult:\n",
    "    \"\"\"\n",
    "    Project possibly-inconsistent one-vs-rest LRs (λ_k) to a Bayes-coherent\n",
    "    multiclass model by estimating log-scores s_k that minimize squared errors\n",
    "    between input log-OVR LRs and model-implied log-OVR LRs with the true\n",
    "    mixture denominator. Then compute posterior P_k ∝ π_k * exp(s_k).\n",
    "\n",
    "    Interpretation:\n",
    "      - s_k acts like log L_k (class-conditional likelihood) up to a global offset.\n",
    "      - The 'rest' likelihood in OVR is the PRIOR-WEIGHTED mixture of other classes.\n",
    "      - Regularization 'reg' is ridge on s (Gaussian prior, stabilizer).\n",
    "    \"\"\"\n",
    "    # ---- Input sanitation / normalization ------------------------------------\n",
    "    pi = np.asarray(priors, dtype=float).copy()\n",
    "    lam = np.asarray(ovr_lr, dtype=float).copy()\n",
    "    K = pi.size\n",
    "    if lam.size != K:\n",
    "        raise ValueError(\"ovr_lr and priors must have same length K.\")\n",
    "    if np.any(lam <= 0):\n",
    "        raise ValueError(\"All OVR LRs must be > 0 (strictly positive).\")\n",
    "\n",
    "    eps = 1e-12\n",
    "    pi = np.clip(pi, eps, 1 - eps)        # avoid 0/1 which break logs and logits\n",
    "    pi = pi / pi.sum()                    # ensure priors sum to 1\n",
    "\n",
    "    # Fix one class as the log-score baseline to resolve the additive constant\n",
    "    if baseline is None:\n",
    "        baseline = int(np.argmax(pi))     # sensible default: most probable prior\n",
    "\n",
    "    # Optional per-class weights for the least-squares fit (confidence on λ_k)\n",
    "    if weights is None:\n",
    "        w = np.ones(K, dtype=float)\n",
    "    else:\n",
    "        w = np.asarray(weights, dtype=float)\n",
    "        if w.size != K:\n",
    "            raise ValueError(\"weights must have length K.\")\n",
    "        w = np.clip(w, eps, None)\n",
    "\n",
    "    # Precompute log priors and helper transforms\n",
    "    log_pi = np.log(pi)\n",
    "    log_one_minus_pi = np.log(1.0 - pi)\n",
    "    log_lambda = np.log(lam)\n",
    "    logit_pi = log_pi - np.log(1.0 - pi)\n",
    "\n",
    "    # ---- Initialization -------------------------------------------------------\n",
    "    # q_init = binary posteriors for each \"k vs not-k\" (your coherence slices)\n",
    "    # If inputs are perfectly coherent, ∑ q_init == 1 and s0_full already solves it.\n",
    "    q_init = expit(logit_pi + log_lambda)\n",
    "\n",
    "    # From P_k ∝ π_k e^{s_k} ⇒ s_k = log P_k - log π_k (up to a constant). Use q_init.\n",
    "    s0_full = np.log(q_init) - np.log(pi)   # defined up to an additive constant\n",
    "    s0_full -= s0_full[baseline]            # fix baseline's s to 0 for identifiability\n",
    "    keep = np.array([i for i in range(K) if i != baseline], dtype=int)\n",
    "    theta0 = s0_full[keep]                  # optimizer coordinates (exclude baseline)\n",
    "\n",
    "    def unpack(theta):\n",
    "        \"\"\"Insert the optimized coordinates back into the full s vector (baseline fixed).\"\"\"\n",
    "        s = np.empty(K, dtype=float)\n",
    "        s[baseline] = 0.0\n",
    "        s[keep] = theta\n",
    "        return s\n",
    "\n",
    "    # ---- Residuals and analytic Jacobian (Gauss–Newton-friendly) -------------\n",
    "    # Residual for class k:\n",
    "    #   r_k = sqrt(w_k) * [ log λ_k - ( s_k - log ∑_{j≠k} π_j e^{s_j} + log(1-π_k) ) ]\n",
    "    # where the middle term is the model's OVR log-LR for k vs rest-mixture.\n",
    "    def residuals_and_jac(theta):\n",
    "        s = unpack(theta)\n",
    "\n",
    "        # Unnormalized log \"joint\" for class k: z_k = log π_k + s_k\n",
    "        z = log_pi + s\n",
    "        # log-sum-exp trick: work in a numerically stable frame\n",
    "        m = np.max(z)\n",
    "        ez = np.exp(z - m)                 # proportional to π_k e^{s_k}, rescaled\n",
    "        S = np.sum(ez)                     # common normalizer (rescaled)\n",
    "        S_minus = S - ez                   # ∑_{j≠k} π_j e^{s_j} (rescaled)\n",
    "        S_minus = np.maximum(S_minus, eps) # guard tiny denominators\n",
    "        logS_minus = np.log(S_minus) + m   # undo rescaling to get true log sum\n",
    "\n",
    "        # Model-implied OVR log-LR for each class k\n",
    "        model_loglr = s - logS_minus + log_one_minus_pi\n",
    "\n",
    "        # Weighted residuals on the log-LR scale (units = \"nats\")\n",
    "        r_core = log_lambda - model_loglr\n",
    "        r = np.sqrt(w) * r_core\n",
    "\n",
    "        # Jacobian J = ∂r / ∂theta (theta excludes baseline s)\n",
    "        # For the full s (including baseline) the partials are:\n",
    "        #   ∂r_k/∂s_k = -sqrt(w_k)\n",
    "        #   ∂r_k/∂s_j (j ≠ k) = sqrt(w_k) * (π_j e^{s_j}) / (∑_{ℓ≠k} π_ℓ e^{s_ℓ})\n",
    "        J = np.zeros((K, K), dtype=float)\n",
    "        np.fill_diagonal(J, -np.sqrt(w))   # diag terms (k wrt s_k)\n",
    "        frac = ez[None, :] / S_minus[:, None]  # broadcasted fraction for off-diagonals\n",
    "        frac[np.arange(K), np.arange(K)] = 0.0 # zero out the j=k entries\n",
    "        J += (np.sqrt(w)[:, None] * frac)\n",
    "        # Drop the baseline column (its s is fixed)\n",
    "        J = J[:, keep]\n",
    "\n",
    "        # Optional L2 (ridge) regularization on theta: adds √reg * theta to residuals,\n",
    "        # and √reg * I to the Jacobian (Tikhonov → better conditioning).\n",
    "        if reg > 0.0:\n",
    "            r = np.concatenate([r, np.sqrt(reg)*theta])\n",
    "            J = np.vstack([J, np.sqrt(reg)*np.eye(theta.size)])\n",
    "        return r, J\n",
    "\n",
    "    # Trust Region Reflective least-squares with analytic Jacobian\n",
    "    res = least_squares(lambda t: residuals_and_jac(t)[0],\n",
    "                        theta0,\n",
    "                        jac=lambda t: residuals_and_jac(t)[1],\n",
    "                        method=\"trf\",\n",
    "                        max_nfev=max_nfev, ftol=ftol, xtol=xtol, gtol=gtol)\n",
    "\n",
    "    # ---- Recover coherent posterior and fitted OVR LRs ------------------------\n",
    "    theta_hat = res.x\n",
    "    s_hat = unpack(theta_hat)               # fitted class log-scores (baseline = 0)\n",
    "    z_hat = log_pi + s_hat                  # log unnormalized posteriors\n",
    "    logZ = logsumexp(z_hat)                 # common log normalizer\n",
    "    posterior = np.exp(z_hat - logZ)        # coherent P_k\n",
    "\n",
    "    # Fitted OVR LRs implied by the model (for reporting / comparison)\n",
    "    exp_z = np.exp(z_hat)\n",
    "    S = np.sum(exp_z)\n",
    "    S_minus_hat = np.maximum(S - exp_z, eps)\n",
    "    model_loglr_hat = s_hat - np.log(S_minus_hat) + log_one_minus_pi\n",
    "    ovr_lr_hat = np.exp(model_loglr_hat)\n",
    "\n",
    "    out = OVRProjectionResult(\n",
    "        posterior=posterior,\n",
    "        log_scores=s_hat,\n",
    "        lr_vs_baseline=np.exp(s_hat),     # LR_{k:baseline}; baseline s=0 ⇒ exp(s_k)\n",
    "        ovr_lr_fitted=ovr_lr_hat,\n",
    "        rmse=float(np.sqrt(np.mean(res.fun**2))),\n",
    "        success=bool(res.success),\n",
    "        message=res.message,\n",
    "        nfev=int(res.nfev),\n",
    "        diagnostics={\n",
    "            \"K\": K,\n",
    "            \"baseline\": baseline,\n",
    "            # Coherence diagnostic: if inputs were coherent, this sum would be 1.\n",
    "            \"sum_q_init\": float(np.sum(q_init)),\n",
    "            \"priors\": pi,\n",
    "            \"input_ovr_lr\": lam,\n",
    "        },\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  Visualization: show pre vs post, annotate Input vs Fitted\n",
    "# ============================================================\n",
    "def stacked_chart_pre_post(pre_test_probabilities, post_testing_probabilities, dx_names,\n",
    "                           input_loglr, fitted_ovr_lr=None, figsize=(6, 6)):\n",
    "    \"\"\"\n",
    "    Visualize how the posterior reallocates probability mass.\n",
    "    Legend shows, per diagnosis:\n",
    "        \"Input OVR LR: <..> | Fitted OVR LR: <..>\"\n",
    "    • input_loglr: what the LLM/literature supplied (possibly inconsistent)\n",
    "    • fitted_ovr_lr: coherent LRs implied by the projected model (optional)\n",
    "    \"\"\"\n",
    "    if not (len(pre_test_probabilities) == len(post_testing_probabilities) == len(dx_names) == len(input_loglr)):\n",
    "        raise ValueError(\"All input arrays must have the same length.\")\n",
    "\n",
    "    pre = np.array(pre_test_probabilities, dtype=float)\n",
    "    post = np.array(post_testing_probabilities, dtype=float)\n",
    "    pre = pre / pre.sum()\n",
    "    post = post / post.sum()\n",
    "\n",
    "    data = [pre, post]\n",
    "    x_labels = [\"Before Info\", \"After Info\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    x = np.arange(len(data))\n",
    "    bottoms = np.zeros(len(data))\n",
    "    width = 0.12\n",
    "\n",
    "    # Keep track of bar tops/bottoms to draw dotted connectors (visual funnel)\n",
    "    bar_tops = {i: [] for i in range(len(dx_names))}\n",
    "    bar_bottoms = {i: [] for i in range(len(dx_names))}\n",
    "\n",
    "    for i, category in enumerate(dx_names):\n",
    "        values = [data_point[i] for data_point in data]\n",
    "        # Annotate Input vs Fitted OVR LRs side-by-side\n",
    "        lr_text = f\"Input OVR LR: {np.exp(input_loglr[i]):.2f}\"\n",
    "        if fitted_ovr_lr is not None:\n",
    "            lr_text += f\" | Fitted OVR LR: {fitted_ovr_lr[i]:.2f}\"\n",
    "        bars = ax.bar(x, values, width=width, bottom=bottoms,\n",
    "                      label=f\"{category} ({lr_text})\")\n",
    "        for bar, value in zip(bars, values):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2,\n",
    "                    bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{value:.2f}\",\n",
    "                    ha=\"center\", va=\"center\", fontsize=10, color=\"white\")\n",
    "            bar_tops[i].append(bar.get_y() + bar.get_height())\n",
    "            bar_bottoms[i].append(bar.get_y())\n",
    "        bottoms += values\n",
    "\n",
    "    # Dotted lines: where each class \"starts\" and \"ends\"\n",
    "    for i in range(len(dx_names)):\n",
    "        ax.plot(x, bar_tops[i], linestyle=\"--\", color=\"gray\", alpha=0.5)\n",
    "        ax.plot(x, bar_bottoms[i], linestyle=\"--\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_title(\"Before-Data vs After-Data Probabilities\")\n",
    "    ax.legend(title=\"Diagnoses\", loc=\"best\", bbox_to_anchor=(0.5, -0.15), ncol=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  Wrapper: read inputs, run either OVR projection (recommended)\n",
    "#  or \"common-reference softmax\" (assumes shared denominator).\n",
    "# ============================================================\n",
    "def generalized_predictor_wrapper(diagnoses, method=\"ovr_projection\", reg=1e-6):\n",
    "    \"\"\"\n",
    "    diagnoses: list of dicts:\n",
    "      [{ 'name': <str>, 'pretest': float in [0,1], 'loglr': float (log OVR LR) }, ...]\n",
    "\n",
    "    method:\n",
    "      - \"ovr_projection\": Bayes‑coherent OVR projection (mixture-aware least squares)\n",
    "      - \"softmax_scores\": treat 'loglr' as log-likelihoods vs a single common reference\n",
    "                          (i.e., already coherent up to a shared constant)\n",
    "    \"\"\"\n",
    "    # Unpack raw inputs\n",
    "    names, pre_test_probs, input_loglr = [], [], []\n",
    "    for d in diagnoses:\n",
    "        names.append(d['name'])\n",
    "        pre_test_probs.append(d['pretest'])\n",
    "        input_loglr.append(d['loglr'])\n",
    "\n",
    "    # Normalize priors; keep original pre_test_probs for reporting\n",
    "    pre = np.array(pre_test_probs, dtype=float)\n",
    "    if pre.sum() <= 0:\n",
    "        raise ValueError(\"Sum of pre-test probabilities must be > 0.\")\n",
    "    priors = pre / pre.sum()\n",
    "    input_loglr = np.array(input_loglr, dtype=float)\n",
    "\n",
    "    if method == \"ovr_projection\":\n",
    "        # Core solver: project inconsistent OVR LRs to a single coherent model\n",
    "        lam = np.exp(input_loglr)\n",
    "        res = project_ovr_to_coherent(priors=priors, ovr_lr=lam, reg=reg)\n",
    "\n",
    "        post = res.posterior\n",
    "        fitted_ovr = res.ovr_lr_fitted\n",
    "        fitted_loglr = np.log(fitted_ovr)\n",
    "\n",
    "        # Basic run diagnostics: optimizer status + coherence check on the init slices\n",
    "        print(f\"OVR projection success: {res.success} (nfev={res.nfev}) | rmse(log-LR)={res.rmse:.4g}\")\n",
    "        print(f\"Baseline class index: {res.diagnostics['baseline']} | sum q_init: {res.diagnostics['sum_q_init']:.6f}\")\n",
    "\n",
    "        # Table: show how inputs were adjusted to become coherent\n",
    "        header = (\n",
    "            f\"{'Diagnosis':<20}{'Pre-Test':<12}{'Norm Pre':<12}\"\n",
    "            f\"{'Input OVR LR':<15}{'Fitted OVR LR':<16}{'Fitted LogLR':<15}{'Post-Test':<12}\"\n",
    "        )\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))\n",
    "        for i, name in enumerate(names):\n",
    "            print(f\"{name:<20}\"\n",
    "                  f\"{pre[i]:<12.3f}{priors[i]:<12.3f}\"\n",
    "                  f\"{np.exp(input_loglr[i]):<15.3f}{fitted_ovr[i]:<16.3f}{fitted_loglr[i]:<15.3f}{post[i]:<12.3f}\")\n",
    "\n",
    "        return {\n",
    "            'names': names,\n",
    "            'pre_test_probs': pre,\n",
    "            'weights_of_evidence': input_loglr,  # keep the original inputs for plotting context\n",
    "            'predicted_probs': post,\n",
    "            'fitted_ovr_lr': fitted_ovr,\n",
    "            'fitted_loglr': fitted_loglr\n",
    "        }\n",
    "\n",
    "    elif method == \"softmax_scores\":\n",
    "        # Alternate path: assume provided loglr are already common-reference scores\n",
    "        # (i.e., log L_k minus a shared constant). Then Bayes is just softmax(log π + loglr).\n",
    "        combined = np.log(priors) + input_loglr\n",
    "        expc = np.exp(combined - np.max(combined))\n",
    "        post = expc / np.sum(expc)\n",
    "\n",
    "        header = (\n",
    "            f\"{'Diagnosis':<20}{'Pre-Test':<12}{'Norm Pre':<12}\"\n",
    "            f\"{'Input LR':<12}{'LogLR':<12}{'Post-Test':<12}\"\n",
    "        )\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))\n",
    "        for i, name in enumerate(names):\n",
    "            print(f\"{name:<20}\"\n",
    "                  f\"{pre[i]:<12.3f}{priors[i]:<12.3f}\"\n",
    "                  f\"{np.exp(input_loglr[i]):<12.3f}{input_loglr[i]:<12.3f}{post[i]:<12.3f}\")\n",
    "\n",
    "        return {\n",
    "            'names': names,\n",
    "            'pre_test_probs': pre,\n",
    "            'weights_of_evidence': input_loglr,\n",
    "            'predicted_probs': post,\n",
    "            'fitted_ovr_lr': None,\n",
    "            'fitted_loglr': None\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "    \n",
    "\n",
    "# ============================================================\n",
    "#  Notebook widget: quick UI to experiment with priors and LRs\n",
    "#  • \"OVR coherent projection\" (recommended) runs the solver\n",
    "#  • \"Common-reference softmax\" assumes scores already share a\n",
    "#    single denominator (no OVR mixture coupling enforced)\n",
    "# ============================================================\n",
    "def create_diagnosis_widget():\n",
    "    diagnosis_count = widgets.IntSlider(value=3, min=1, max=12, step=1, description=\"Diagnoses\")\n",
    "    method_dd = widgets.Dropdown(options=[('OVR coherent projection','ovr_projection'),\n",
    "                                          ('Common-reference softmax','softmax_scores')],\n",
    "                                 value='ovr_projection', description='Method')\n",
    "    # Ridge strength slider (log-scale). ↑ reg = more shrinkage / stability.\n",
    "    reg_slider = widgets.FloatLogSlider(value=1e-6, base=10, min=-12, max=-2, step=0.5,\n",
    "                                        description=\"Reg (L2)\", readout_format=\".1e\")\n",
    "\n",
    "    container = VBox()\n",
    "    chart_output = Output()\n",
    "\n",
    "    def update_widgets(change):\n",
    "        if change['name'] == 'value':\n",
    "            children = []\n",
    "            for i in range(change['new']):\n",
    "                name_widget = widgets.Text(value=f\"Diagnosis {i+1}\", description=\"Name:\")\n",
    "                pretest_widget = widgets.FloatSlider(value=0.33, min=0.0, max=1.0, step=0.01,\n",
    "                                                     description=\"Pre-Test:\", readout_format='.2f')\n",
    "                # Slider shows LR on a log scale; we convert to log() at readout.\n",
    "                lr_widget = widgets.FloatLogSlider(value=1.0, base=np.e, min=-5.0, max=5.0, step=0.1,\n",
    "                                                   description=\"OVR LR:\", readout=True, readout_format=\".2f\")\n",
    "                children.append(VBox([name_widget, pretest_widget, lr_widget]))\n",
    "            container.children = tuple(children)\n",
    "\n",
    "    diagnosis_count.observe(update_widgets, names='value')\n",
    "    update_widgets({'name': 'value', 'new': diagnosis_count.value})\n",
    "\n",
    "    def gather_inputs(_):\n",
    "        # Assemble inputs from the UI\n",
    "        diagnoses = []\n",
    "        for box in container.children:\n",
    "            name = box.children[0].value\n",
    "            pretest = box.children[1].value\n",
    "            loglr = np.log(box.children[2].value)  # store log OVR LR\n",
    "            diagnoses.append({'name': name, 'pretest': pretest, 'loglr': loglr})\n",
    "\n",
    "        chart_output.clear_output()\n",
    "        with chart_output:\n",
    "            # Run chosen method and plot pre vs post; legend shows Input vs Fitted LRs\n",
    "            results = generalized_predictor_wrapper(diagnoses, method=method_dd.value, reg=reg_slider.value)\n",
    "            stacked_chart_pre_post(results['pre_test_probs'],\n",
    "                                   results['predicted_probs'],\n",
    "                                   results['names'],\n",
    "                                   results['weights_of_evidence'],\n",
    "                                   fitted_ovr_lr=results['fitted_ovr_lr'])\n",
    "\n",
    "    calculate_button = widgets.Button(description=\"Calculate\")\n",
    "    calculate_button.on_click(gather_inputs)\n",
    "\n",
    "    left = VBox([diagnosis_count, method_dd, reg_slider, container, calculate_button])\n",
    "    return HBox([left, chart_output])\n",
    "\n",
    "\n",
    "# Build & display widget\n",
    "diagnosis_widget = create_diagnosis_widget()\n",
    "display(diagnosis_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
