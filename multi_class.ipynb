{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "auto_run": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba04fa9e4534d39beb099feb3bd5239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=1, description='Diagnoses', max=10, min=1), VBox(children=(VBox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import numpy as np\n",
    "from ipywidgets import interact, widgets, VBox, HBox, Layout, Output\n",
    "\n",
    "plt.style.use('science')\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "certainty_estimates = {\n",
    "    \"HIGHLY_UNLIKELY\": 0.119,\n",
    "    \"UNLIKELY\": 0.269,\n",
    "    \"UNCERTAIN\": 0.5,\n",
    "    \"LIKELY\": 0.731,\n",
    "    \"HIGHLY_LIKELY\": 0.881\n",
    "}\n",
    "\n",
    "def softmax_regression_predict(pre_test_probabilities, weights_of_evidence):\n",
    "    \"\"\"\n",
    "    Predict probabilities using a multinomial logistic regression model (softmax regression).\n",
    "    \n",
    "    Parameters:\n",
    "        pre_test_probabilities (list of float): Pre-test probabilities (baseline probabilities before including predictors).\n",
    "        weights_of_evidence (list of float): Linear predictors (log-odds contributions) for each class.\n",
    "    \n",
    "    Returns:\n",
    "        list of float: Predicted probabilities for each class (summing to 1).\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the lengths of inputs don't match or if pre_test_probabilities contain invalid values.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(pre_test_probabilities) != len(weights_of_evidence):\n",
    "        raise ValueError(\"The lengths of pre_test_probabilities and weights_of_evidence must be the same (equal to the number of diagnoses).\")\n",
    "    \n",
    "    if not all(0 <= prob <= 1 for prob in pre_test_probabilities):\n",
    "        raise ValueError(\"All pre_test_probabilities must be between 0 and 1.\")\n",
    "    \n",
    "    combined = np.log(pre_test_probabilities) + np.array(weights_of_evidence)\n",
    "    \n",
    "    # Compute probabilities using the softmax function\n",
    "    exp_combined = np.exp(combined - np.max(combined))  # Stability trick to avoid overflow\n",
    "    probabilities = exp_combined / np.sum(exp_combined)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def stacked_chart_pre_post(pre_test_probabilities, post_testing_probabilities, dx_names, weights_of_evidence, figsize=(6, 6)):\n",
    "    \"\"\"Visualize the changes in probabilities with dotted lines connecting the top and bottom of pre- and post-test bars.\"\"\"\n",
    "    # Check that input lengths match\n",
    "    if not (len(pre_test_probabilities) == len(post_testing_probabilities) == len(dx_names) == len(weights_of_evidence)):\n",
    "        raise ValueError(\"All input arrays must have the same length.\")\n",
    "\n",
    "    # Normalize the probabilities to ensure they sum to 1\n",
    "    pre_test_probabilities = np.array(pre_test_probabilities) / np.sum(pre_test_probabilities)\n",
    "    post_testing_probabilities = np.array(post_testing_probabilities) / np.sum(post_testing_probabilities)\n",
    "\n",
    "    # Combine the data for stacked bar charts\n",
    "    data = [pre_test_probabilities, post_testing_probabilities]\n",
    "\n",
    "    # Labels for the x-axis\n",
    "    x_labels = [\"Before Info\", \"After Info\"]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Stacked bar chart\n",
    "    x = np.arange(len(data))  # Positions for \"Before\" and \"After\"\n",
    "    bottoms = np.zeros(len(data))  # To track stack heights\n",
    "    width = 0.12  # Increased bar width for better visibility\n",
    "\n",
    "    # Store top and bottom coordinates for dotted line drawing\n",
    "    bar_tops = {i: [] for i in range(len(dx_names))}\n",
    "    bar_bottoms = {i: [] for i in range(len(dx_names))}\n",
    "\n",
    "    # Add bars and annotate probabilities\n",
    "    for i, category in enumerate(dx_names):\n",
    "        values = [data_point[i] for data_point in data]\n",
    "        bars = ax.bar(x, values, width=width, bottom=bottoms, label=f\"{category} (LogLR: {weights_of_evidence[i]:.2f})\")\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            # Add text inside each bar\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_y() + bar.get_height() / 2,\n",
    "                f\"{value:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=10,\n",
    "                color=\"white\"\n",
    "            )\n",
    "            # Store the top and bottom of each bar\n",
    "            bar_tops[i].append(bar.get_y() + bar.get_height())\n",
    "            bar_bottoms[i].append(bar.get_y())\n",
    "\n",
    "        bottoms += values\n",
    "\n",
    "    # Add dotted lines connecting the top and bottom of each category\n",
    "    for i in range(len(dx_names)):\n",
    "        ax.plot(\n",
    "            x,  # x-coordinates for \"Before\" and \"After\"\n",
    "            bar_tops[i],  # y-coordinates for the tops of the bars\n",
    "            linestyle=\"--\", color=\"gray\", alpha=0.5\n",
    "        )\n",
    "        ax.plot(\n",
    "            x,  # x-coordinates for \"Before\" and \"After\"\n",
    "            bar_bottoms[i],  # y-coordinates for the bottoms of the bars\n",
    "            linestyle=\"--\", color=\"gray\", alpha=0.5\n",
    "        )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_title(\"Before-Data vs After-Data Probabilities\")\n",
    "\n",
    "    # Move the legend below the chart\n",
    "    ax.legend(title=\"Diagnoses\", loc=\"best\", bbox_to_anchor=(0.5, -0.15), ncol=1)\n",
    "\n",
    "    # Adjust layout to avoid overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generalized wrapper function for n diagnoses\n",
    "def generalized_predictor_wrapper(diagnoses):\n",
    "    \"\"\"\n",
    "    Wrapper function to compute post-test probabilities for all diagnoses using softmax regression.\n",
    "\n",
    "    Parameters:\n",
    "        diagnoses (list): List of dictionaries, each containing the details of a diagnosis.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing names, normalized pre-test probabilities, weights of evidence, and post-test probabilities.\n",
    "    \"\"\"\n",
    "    # Gather pre-test probabilities and cumulative weights of evidence\n",
    "    pre_test_probs = []\n",
    "    weights_of_evidence = []\n",
    "    names = []\n",
    "\n",
    "    for diagnosis in diagnoses:\n",
    "        name = diagnosis['name']\n",
    "        pre_test_prob = certainty_estimates[diagnosis['pretest']]\n",
    "        major_positive = diagnosis['major_positive']\n",
    "        major_negative = diagnosis['major_negative']\n",
    "        minor_positive = diagnosis['minor_positive']\n",
    "        minor_negative = diagnosis['minor_negative']\n",
    "\n",
    "        # Calculate the cumulative weight of evidence for this diagnosis\n",
    "        weight_of_evidence = (\n",
    "            major_positive \n",
    "            - (major_negative / 2) \n",
    "            + (minor_positive / 3) \n",
    "            - (minor_negative / 6)\n",
    "        )\n",
    "\n",
    "        # Append data\n",
    "        pre_test_probs.append(pre_test_prob)\n",
    "        weights_of_evidence.append(weight_of_evidence)\n",
    "        names.append(name)\n",
    "\n",
    "    # Normalize pre-test probabilities\n",
    "    pre_test_sum = sum(pre_test_probs)\n",
    "    norm_pre_test_probs = [p / pre_test_sum for p in pre_test_probs]\n",
    "\n",
    "    # Use softmax regression to calculate post-test probabilities\n",
    "    predicted_probs = softmax_regression_predict(pre_test_probs, weights_of_evidence)\n",
    "\n",
    "    # Create result dictionary\n",
    "    results = {\n",
    "        'names': names,\n",
    "        'pre_test_probs': pre_test_probs,\n",
    "        'norm_pre_test_probs': norm_pre_test_probs,\n",
    "        'weights_of_evidence': weights_of_evidence,\n",
    "        'predicted_probs': predicted_probs\n",
    "    }\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"{'Diagnosis':<20}{'Pre-Test Prob':<15}{'Norm Pre-Test Prob':<20}{'LR':<15}{'LogLR':<15}{'Post-Test Prob':<15}\")\n",
    "    print(\"-\" * 95)\n",
    "    for i, name in enumerate(names):\n",
    "        print(f\"{name:<20}{pre_test_probs[i]:<15.2f}{norm_pre_test_probs[i]:<20.2f}{np.exp(weights_of_evidence[i]):<15.2f}{weights_of_evidence[i]:<15.2f}{predicted_probs[i]:<15.2f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Dynamic widget for n diagnoses\n",
    "def create_diagnosis_widget():\n",
    "    \"\"\"\n",
    "    Creates an interactive widget for entering diagnosis details and calculating post-test probabilities\n",
    "    using softmax regression, displaying the stacked chart dynamically.\n",
    "    \n",
    "    Returns:\n",
    "        VBox: A vertical box containing the interactive widget.\n",
    "    \"\"\"\n",
    "    # Define dynamic widgets for n diagnoses\n",
    "    diagnosis_count = widgets.IntSlider(value=1, min=1, max=10, step=1, description=\"Diagnoses\")\n",
    "    container = VBox()\n",
    "    chart_output = Output()  # Output widget to display the chart\n",
    "\n",
    "    # Function to update the widgets based on the number of diagnoses\n",
    "    def update_widgets(change):\n",
    "        if change['name'] == 'value':  # Ensure the change is triggered by the slider\n",
    "            container.children = []  # Clear the container before updating\n",
    "            for i in range(change['new']):  # Iterate over the new diagnosis count\n",
    "                name_widget = widgets.Text(value=f\"Diagnosis {i+1}\", description=\"Name:\")\n",
    "                pretest_widget = widgets.Dropdown(\n",
    "                    options=['HIGHLY_UNLIKELY', 'UNLIKELY', 'UNCERTAIN', 'LIKELY', 'HIGHLY_LIKELY'],\n",
    "                    value='UNCERTAIN',\n",
    "                    description=\"Pre-Test:\"\n",
    "                )\n",
    "                major_pos_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Major+\")\n",
    "                major_neg_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Major-\")\n",
    "                minor_pos_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Minor+\")\n",
    "                minor_neg_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Minor-\")\n",
    "\n",
    "                # Combine all widgets for one diagnosis\n",
    "                diagnosis_box = VBox([name_widget, pretest_widget, major_pos_widget, major_neg_widget, minor_pos_widget, minor_neg_widget])\n",
    "                container.children += (diagnosis_box,)  # Add to the container\n",
    "\n",
    "    # Observe changes in the slider and update widgets accordingly\n",
    "    diagnosis_count.observe(update_widgets, names='value')\n",
    "\n",
    "    # Trigger an initial update\n",
    "    update_widgets({'name': 'value', 'new': diagnosis_count.value})\n",
    "\n",
    "    # Function to gather inputs from the widgets\n",
    "    def gather_inputs():\n",
    "        diagnoses = []\n",
    "        for diagnosis_box in container.children:\n",
    "            name = diagnosis_box.children[0].value\n",
    "            pretest = diagnosis_box.children[1].value\n",
    "            major_positive = diagnosis_box.children[2].value\n",
    "            major_negative = diagnosis_box.children[3].value\n",
    "            minor_positive = diagnosis_box.children[4].value\n",
    "            minor_negative = diagnosis_box.children[5].value\n",
    "            diagnoses.append({\n",
    "                'name': name,\n",
    "                'pretest': pretest,\n",
    "                'major_positive': major_positive,\n",
    "                'major_negative': major_negative,\n",
    "                'minor_positive': minor_positive,\n",
    "                'minor_negative': minor_negative\n",
    "            })\n",
    "\n",
    "        # Clear chart output before displaying a new one\n",
    "        chart_output.clear_output()\n",
    "\n",
    "        # Compute results and display chart\n",
    "        with chart_output:\n",
    "            results = generalized_predictor_wrapper(diagnoses)\n",
    "            stacked_chart_pre_post(\n",
    "                results['pre_test_probs'],\n",
    "                results['predicted_probs'],\n",
    "                results['names'],\n",
    "                results['weights_of_evidence']\n",
    "            )\n",
    "\n",
    "    # Add a button to trigger the calculation\n",
    "    calculate_button = widgets.Button(description=\"Calculate\")\n",
    "    calculate_button.on_click(lambda x: gather_inputs())\n",
    "\n",
    "    # Combine the slider, container, and calculate button\n",
    "    return HBox([VBox([diagnosis_count, container, calculate_button]), chart_output])\n",
    "\n",
    "\n",
    "diagnosis_widget = create_diagnosis_widget()\n",
    "display(diagnosis_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004ef9913d844be8b9916a29949ddcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=3, description='Diagnoses', max=12, min=2), FloatLogSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import numpy as np\n",
    "from ipywidgets import interact, widgets, VBox, HBox, Layout, Output\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.special import expit, logsumexp\n",
    "\n",
    "plt.style.use('science')\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Qualitative pretest → numeric prior (edit these if you recalibrate)\n",
    "# --------------------------------------------------------------------\n",
    "certainty_estimates = {\n",
    "    \"HIGHLY_UNLIKELY\": 0.119,\n",
    "    \"UNLIKELY\":        0.269,\n",
    "    \"UNCERTAIN\":       0.500,\n",
    "    \"LIKELY\":          0.731,\n",
    "    \"HIGHLY_LIKELY\":   0.881\n",
    "}\n",
    "\n",
    "# ====================================================================\n",
    "# Bayes‑coherent OVR projection (mixture‑aware coupling)\n",
    "#   Inputs:\n",
    "#     priors π_k  (sum to 1)\n",
    "#     ovr_lr λ_k  (LR for k vs \"not k\")  -- here λ_k = exp(weight_of_evidence_k)\n",
    "#   Output:\n",
    "#     coherent posterior P_k ∝ π_k * exp(s_k)\n",
    "#     fitted OVR LRs implied by the model\n",
    "# ====================================================================\n",
    "\n",
    "@dataclass\n",
    "class OVRProjectionResult:\n",
    "    posterior: np.ndarray                 # coherent P_k\n",
    "    log_scores: np.ndarray                # s_k (baseline fixed to 0)\n",
    "    lr_vs_baseline: np.ndarray            # LR_{k:baseline} = exp(s_k)\n",
    "    ovr_lr_fitted: np.ndarray             # coherent OVR LRs implied by s\n",
    "    rmse: float                           # sqrt(mean(residual^2)) on log-LR scale\n",
    "    success: bool\n",
    "    message: str\n",
    "    nfev: int\n",
    "    diagnostics: Dict[str, Any]\n",
    "\n",
    "def _project_ovr_to_coherent(\n",
    "    priors: np.ndarray,\n",
    "    ovr_lr: np.ndarray,\n",
    "    weights: Optional[np.ndarray] = None,\n",
    "    baseline: Optional[int] = None,\n",
    "    reg: float = 1e-6,\n",
    "    max_nfev: int = 200,\n",
    "    ftol: float = 1e-10,\n",
    "    xtol: float = 1e-10,\n",
    "    gtol: float = 1e-10,\n",
    ") -> OVRProjectionResult:\n",
    "    pi = np.asarray(priors, dtype=float).copy()\n",
    "    lam = np.asarray(ovr_lr, dtype=float).copy()\n",
    "    K = pi.size\n",
    "    if K < 2:\n",
    "        raise ValueError(\"Need at least 2 diagnoses for OVR.\")\n",
    "    if lam.size != K:\n",
    "        raise ValueError(\"ovr_lr and priors must have the same length.\")\n",
    "    if np.any(lam <= 0):\n",
    "        raise ValueError(\"All OVR LRs must be > 0.\")\n",
    "\n",
    "    eps = 1e-12\n",
    "    pi = np.clip(pi, eps, 1 - eps)\n",
    "    pi = pi / pi.sum()\n",
    "    if baseline is None:\n",
    "        baseline = int(np.argmax(pi))\n",
    "\n",
    "    if weights is None:\n",
    "        w = np.ones(K, dtype=float)\n",
    "    else:\n",
    "        w = np.asarray(weights, dtype=float)\n",
    "        if w.size != K:\n",
    "            raise ValueError(\"weights must have length K.\")\n",
    "        w = np.clip(w, eps, None)\n",
    "\n",
    "    log_pi = np.log(pi)\n",
    "    log_one_minus_pi = np.log(1.0 - pi)\n",
    "    log_lambda = np.log(lam)\n",
    "    logit_pi = log_pi - np.log(1.0 - pi)\n",
    "\n",
    "    # Initialize with per-binary posteriors (the “slices”); exact if coherent\n",
    "    q_init = expit(logit_pi + log_lambda)\n",
    "    s0_full = np.log(q_init) - np.log(pi)      # s up to a constant\n",
    "    s0_full -= s0_full[baseline]               # fix baseline to 0\n",
    "    keep = np.array([i for i in range(K) if i != baseline], dtype=int)\n",
    "    theta0 = s0_full[keep]\n",
    "\n",
    "    def unpack(theta):\n",
    "        s = np.empty(K, dtype=float)\n",
    "        s[baseline] = 0.0\n",
    "        s[keep] = theta\n",
    "        return s\n",
    "\n",
    "    def residuals_and_jac(theta):\n",
    "        s = unpack(theta)\n",
    "        z = log_pi + s\n",
    "        m = np.max(z)\n",
    "        ez = np.exp(z - m)                 # ∝ π_k e^{s_k}\n",
    "        S = np.sum(ez)\n",
    "        S_minus = np.maximum(S - ez, eps)  # ∑_{j≠k} π_j e^{s_j}\n",
    "        logS_minus = np.log(S_minus) + m\n",
    "\n",
    "        model_loglr = s - logS_minus + log_one_minus_pi      # OVR model log-LR\n",
    "        r = np.sqrt(w) * (log_lambda - model_loglr)\n",
    "\n",
    "        # Analytic Jacobian\n",
    "        J = np.zeros((K, K), dtype=float)\n",
    "        np.fill_diagonal(J, -np.sqrt(w))\n",
    "        frac = ez[None, :] / S_minus[:, None]\n",
    "        frac[np.arange(K), np.arange(K)] = 0.0\n",
    "        J += (np.sqrt(w)[:, None] * frac)\n",
    "        J = J[:, keep]\n",
    "\n",
    "        if reg > 0.0:\n",
    "            r = np.concatenate([r, np.sqrt(reg)*theta])\n",
    "            J = np.vstack([J, np.sqrt(reg)*np.eye(theta.size)])\n",
    "        return r, J\n",
    "\n",
    "    res = least_squares(lambda t: residuals_and_jac(t)[0],\n",
    "                        theta0,\n",
    "                        jac=lambda t: residuals_and_jac(t)[1],\n",
    "                        method=\"trf\",\n",
    "                        max_nfev=max_nfev, ftol=ftol, xtol=xtol, gtol=gtol)\n",
    "\n",
    "    theta_hat = res.x\n",
    "    s_hat = unpack(theta_hat)\n",
    "    z_hat = log_pi + s_hat\n",
    "    posterior = np.exp(z_hat - logsumexp(z_hat))\n",
    "\n",
    "    exp_z = np.exp(z_hat)\n",
    "    S = np.sum(exp_z)\n",
    "    S_minus_hat = np.maximum(S - exp_z, eps)\n",
    "    model_loglr_hat = s_hat - np.log(S_minus_hat) + log_one_minus_pi\n",
    "    ovr_lr_hat = np.exp(model_loglr_hat)\n",
    "\n",
    "    return OVRProjectionResult(\n",
    "        posterior=posterior,\n",
    "        log_scores=s_hat,\n",
    "        lr_vs_baseline=np.exp(s_hat),\n",
    "        ovr_lr_fitted=ovr_lr_hat,\n",
    "        rmse=float(np.sqrt(np.mean(res.fun**2))),\n",
    "        success=bool(res.success),\n",
    "        message=res.message,\n",
    "        nfev=int(res.nfev),\n",
    "        diagnostics={\n",
    "            \"K\": K,\n",
    "            \"baseline\": baseline,\n",
    "            \"sum_q_init\": float(np.sum(q_init)),  # =1 if inputs coherent\n",
    "            \"priors\": pi,\n",
    "            \"input_ovr_lr\": lam,\n",
    "        },\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Visualization: show Input vs Fitted OVR LR, pre vs post bars\n",
    "# -------------------------------------------------------------\n",
    "def _stacked_chart_pre_post(pre_test_probabilities, post_testing_probabilities, dx_names,\n",
    "                            input_loglr, fitted_ovr_lr=None, figsize=(6, 6)):\n",
    "    if not (len(pre_test_probabilities) == len(post_testing_probabilities) == len(dx_names) == len(input_loglr)):\n",
    "        raise ValueError(\"All input arrays must have the same length.\")\n",
    "\n",
    "    pre = np.array(pre_test_probabilities, dtype=float)\n",
    "    post = np.array(post_testing_probabilities, dtype=float)\n",
    "    pre = pre / pre.sum()\n",
    "    post = post / post.sum()\n",
    "\n",
    "    data = [pre, post]\n",
    "    x_labels = [\"Before Info\", \"After Info\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    x = np.arange(len(data))\n",
    "    bottoms = np.zeros(len(data))\n",
    "    width = 0.12\n",
    "\n",
    "    bar_tops = {i: [] for i in range(len(dx_names))}\n",
    "    bar_bottoms = {i: [] for i in range(len(dx_names))}\n",
    "\n",
    "    for i, category in enumerate(dx_names):\n",
    "        values = [data_point[i] for data_point in data]\n",
    "        legend_txt = f\"Input OVR LR: {np.exp(input_loglr[i]):.2f}\"\n",
    "        if fitted_ovr_lr is not None:\n",
    "            legend_txt += f\" | Fitted OVR LR: {fitted_ovr_lr[i]:.2f}\"\n",
    "        bars = ax.bar(x, values, width=width, bottom=bottoms,\n",
    "                      label=f\"{category} ({legend_txt})\")\n",
    "        for bar, value in zip(bars, values):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2,\n",
    "                    bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{value:.2f}\",\n",
    "                    ha=\"center\", va=\"center\", fontsize=10, color=\"white\")\n",
    "            bar_tops[i].append(bar.get_y() + bar.get_height())\n",
    "            bar_bottoms[i].append(bar.get_y())\n",
    "        bottoms += values\n",
    "\n",
    "    for i in range(len(dx_names)):\n",
    "        ax.plot(x, bar_tops[i], linestyle=\"--\", color=\"gray\", alpha=0.5)\n",
    "        ax.plot(x, bar_bottoms[i], linestyle=\"--\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_title(\"Before-Data vs After-Data Probabilities\")\n",
    "    ax.legend(title=\"Diagnoses\", loc=\"best\", bbox_to_anchor=(0.5, -0.15), ncol=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ====================================================================\n",
    "# Your app‑specific mapping from qualitative finding counts to weights\n",
    "#   Here we interpret 'weight_of_evidence' as log OVR LR for class k.\n",
    "#   Edit the coefficients if you recalibrate those qualitative bins.\n",
    "# ====================================================================\n",
    "def _compute_weight_of_evidence(major_positive, major_negative, minor_positive, minor_negative):\n",
    "    # Example linear rule you supplied (units: log‑LR for k vs not‑k)\n",
    "    return (\n",
    "        major_positive\n",
    "        - (major_negative / 2)\n",
    "        + (minor_positive / 3)\n",
    "        - (minor_negative / 6)\n",
    "    )\n",
    "\n",
    "# ====================================================================\n",
    "# Wrapper (OVR projection): assembles inputs, runs solver, prints table\n",
    "# ====================================================================\n",
    "def generalized_predictor_wrapper(diagnoses, reg=1e-6):\n",
    "    \"\"\"\n",
    "    diagnoses: list of dicts like\n",
    "      {'name': str, 'pretest': one of certainty_estimates keys,\n",
    "       'major_positive': int, 'major_negative': int, 'minor_positive': int, 'minor_negative': int}\n",
    "    \"\"\"\n",
    "    names, pre_test_probs, loglr_input = [], [], []\n",
    "\n",
    "    # Build priors and per‑class cumulative log OVR LR\n",
    "    for d in diagnoses:\n",
    "        names.append(d['name'])\n",
    "        pre_test_probs.append(certainty_estimates[d['pretest']])\n",
    "        loglr_input.append(_compute_weight_of_evidence(\n",
    "            d['major_positive'], d['major_negative'], d['minor_positive'], d['minor_negative']\n",
    "        ))\n",
    "\n",
    "    pre = np.array(pre_test_probs, dtype=float)\n",
    "    priors = pre / np.sum(pre)\n",
    "    loglr_input = np.array(loglr_input, dtype=float)\n",
    "    lam_input = np.exp(loglr_input)\n",
    "\n",
    "    # Project to a single coherent model\n",
    "    res = _project_ovr_to_coherent(priors=priors, ovr_lr=lam_input, reg=reg)\n",
    "\n",
    "    post = res.posterior\n",
    "    fitted_ovr = res.ovr_lr_fitted\n",
    "    fitted_loglr = np.log(fitted_ovr)\n",
    "\n",
    "    # Table: Input vs Fitted OVR LR + Fitted LogLR\n",
    "    header = (\n",
    "        f\"{'Diagnosis':<20}{'Pre-Test':<12}{'Norm Pre':<12}\"\n",
    "        f\"{'Input OVR LR':<15}{'Fitted OVR LR':<16}{'Fitted LogLR':<15}{'Post-Test':<12}\"\n",
    "    )\n",
    "    print(f\"OVR projection success: {res.success} (nfev={res.nfev}) | rmse(log-LR)={res.rmse:.4g}\")\n",
    "    print(f\"Baseline class index: {res.diagnostics['baseline']} | sum q_init: {res.diagnostics['sum_q_init']:.6f}\")\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for i, name in enumerate(names):\n",
    "        print(f\"{name:<20}\"\n",
    "              f\"{pre[i]:<12.3f}{priors[i]:<12.3f}\"\n",
    "              f\"{lam_input[i]:<15.3f}{fitted_ovr[i]:<16.3f}{fitted_loglr[i]:<15.3f}{post[i]:<12.3f}\")\n",
    "\n",
    "    return {\n",
    "        'names': names,\n",
    "        'pre_test_probs': pre,                # raw priors (not yet normalized)\n",
    "        'norm_pre_test_probs': priors,        # normalized priors\n",
    "        'weights_of_evidence': loglr_input,   # input log OVR LR (for legend)\n",
    "        'predicted_probs': post,\n",
    "        'fitted_ovr_lr': fitted_ovr,\n",
    "        'fitted_loglr': fitted_loglr\n",
    "    }\n",
    "\n",
    "# ====================================================================\n",
    "# Interactive widget\n",
    "# ====================================================================\n",
    "def create_diagnosis_widget():\n",
    "    # OVR needs at least 2 classes\n",
    "    diagnosis_count = widgets.IntSlider(value=3, min=2, max=12, step=1, description=\"Diagnoses\")\n",
    "    reg_slider = widgets.FloatLogSlider(value=1e-6, base=10, min=-12, max=-2, step=0.5,\n",
    "                                        description=\"Reg (L2)\", readout_format=\".1e\")\n",
    "\n",
    "    container = VBox()\n",
    "    chart_output = Output()\n",
    "\n",
    "    def update_widgets(change):\n",
    "        if change['name'] == 'value':\n",
    "            children = []\n",
    "            for i in range(change['new']):\n",
    "                name_widget = widgets.Text(value=f\"Diagnosis {i+1}\", description=\"Name:\")\n",
    "                pretest_widget = widgets.Dropdown(\n",
    "                    options=['HIGHLY_UNLIKELY', 'UNLIKELY', 'UNCERTAIN', 'LIKELY', 'HIGHLY_LIKELY'],\n",
    "                    value='UNCERTAIN', description=\"Pre-Test:\"\n",
    "                )\n",
    "                major_pos_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Major+\")\n",
    "                major_neg_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Major-\")\n",
    "                minor_pos_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Minor+\")\n",
    "                minor_neg_widget = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"Minor-\")\n",
    "                children.append(VBox([name_widget, pretest_widget,\n",
    "                                      major_pos_widget, major_neg_widget,\n",
    "                                      minor_pos_widget, minor_neg_widget]))\n",
    "            container.children = tuple(children)\n",
    "\n",
    "    diagnosis_count.observe(update_widgets, names='value')\n",
    "    update_widgets({'name': 'value', 'new': diagnosis_count.value})\n",
    "\n",
    "    def gather_inputs(_=None):\n",
    "        diagnoses = []\n",
    "        for box in container.children:\n",
    "            diagnoses.append({\n",
    "                'name':            box.children[0].value,\n",
    "                'pretest':         box.children[1].value,\n",
    "                'major_positive':  box.children[2].value,\n",
    "                'major_negative':  box.children[3].value,\n",
    "                'minor_positive':  box.children[4].value,\n",
    "                'minor_negative':  box.children[5].value\n",
    "            })\n",
    "\n",
    "        chart_output.clear_output()\n",
    "        with chart_output:\n",
    "            results = generalized_predictor_wrapper(diagnoses, reg=float(reg_slider.value))\n",
    "            _stacked_chart_pre_post(\n",
    "                results['pre_test_probs'],\n",
    "                results['predicted_probs'],\n",
    "                results['names'],\n",
    "                results['weights_of_evidence'],     # input log OVR LR (for legend)\n",
    "                fitted_ovr_lr=results['fitted_ovr_lr']\n",
    "            )\n",
    "\n",
    "    calculate_button = widgets.Button(description=\"Calculate\")\n",
    "    calculate_button.on_click(gather_inputs)\n",
    "\n",
    "    left = VBox([diagnosis_count, reg_slider, container, calculate_button])\n",
    "    return HBox([left, chart_output])\n",
    "\n",
    "\n",
    "diagnosis_widget = create_diagnosis_widget()\n",
    "display(diagnosis_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
